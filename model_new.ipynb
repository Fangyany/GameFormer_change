{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch import nn, optim\n",
    "from GameFormer.predictor import GameFormer\n",
    "from torch.utils.data import DataLoader\n",
    "from GameFormer.train_utils import *\n",
    "\n",
    "num_neighbors = 20\n",
    "batch_size = 32\n",
    "# set up data loaders\n",
    "train_path = 'nuplan/processed_data/train'\n",
    "train_files = [f for d in os.listdir(train_path) for f in glob.glob(os.path.join(train_path, d, \"*.npz\"))]\n",
    "train_set = DrivingData(train_files, num_neighbors)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1690 [00:26<?, ?batch/s]\n"
     ]
    }
   ],
   "source": [
    "with tqdm(train_loader, desc=\"Training\", unit=\"batch\") as data_epoch:\n",
    "    for batch in data_epoch:\n",
    "        # prepare data\n",
    "        inputs = {\n",
    "            'ego_agent_past': batch[0].to('cuda'),\n",
    "            'neighbor_agents_past': batch[1].to('cuda'),\n",
    "            'map_lanes': batch[2].to('cuda'),\n",
    "            'map_crosswalks': batch[3].to('cuda'),\n",
    "            'route_lanes': batch[4].to('cuda')\n",
    "        }\n",
    "\n",
    "        ego_future = batch[5].to('cuda')\n",
    "        neighbors_future = batch[6].to('cuda')\n",
    "        neighbors_future_valid = torch.ne(neighbors_future[..., :2], 0)\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### agent encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GameFormer.predictor_modules import *\n",
    "\n",
    "# shape = (32, T, 7) = (x, y, heading, vx, vy, ax, ay)\n",
    "ego = inputs['ego_agent_past']   \n",
    "# shape = (32, N, T, 11) = (x, y, heading, vx, vy, yaw, length, width, 1, 0, 0)   \n",
    "neighbors = inputs['neighbor_agents_past']    \n",
    "# shape = (32, 1+N, T, 5) = (x, y, heading, vx, vy)\n",
    "actors = torch.cat([ego[:, None, :, :5], neighbors[..., :5]], dim=1)\n",
    "\n",
    "ego_encoder = AgentEncoder(agent_dim=7).cuda()  # LSTM\n",
    "# shape = (32, 256)\n",
    "encoded_ego = ego_encoder(ego)\n",
    "\n",
    "agent_encoder = AgentEncoder(agent_dim=11).cuda()  # LSTM\n",
    "# shape = (N, 32, 256)\n",
    "encoded_neighbors = [agent_encoder(neighbors[:, i]) for i in range(neighbors.shape[1])]\n",
    "\n",
    "# shape = (32, N+1, 256)\n",
    "encoded_actors = torch.stack([encoded_ego] + encoded_neighbors, dim=1)  \n",
    "actors_mask = torch.eq(actors[:, :, -1].sum(-1), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### map encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lane_len = 50\n",
    "_lane_feature = 7\n",
    "_crosswalk_len = 30\n",
    "_crosswalk_feature = 3\n",
    "\n",
    "map_lanes = inputs['map_lanes']    # shape = (32, 40, 50, 7)\n",
    "map_crosswalks = inputs['map_crosswalks']   # shape = (32, 5, 30, 3)\n",
    "\n",
    "\n",
    "lane_encoder = VectorMapEncoder(_lane_feature, _lane_len).cuda()\n",
    "# shape = (32, 200, 256)\n",
    "encoded_map_lanes, lanes_mask = lane_encoder(map_lanes)\n",
    "\n",
    "crosswalk_encoder = VectorMapEncoder(_crosswalk_feature, _crosswalk_len).cuda()\n",
    "# shape = (32, 15, 256)\n",
    "encoded_map_crosswalks, crosswalks_mask = crosswalk_encoder(map_crosswalks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### attention fusion encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape = (32, 236, 256)\n",
    "input = torch.cat([encoded_actors, encoded_map_lanes, encoded_map_crosswalks], dim=1)\n",
    "mask = torch.cat([actors_mask, lanes_mask, crosswalks_mask], dim=1)\n",
    "\n",
    "dim, layers, heads, dropout = 256, 6, 8, 0.1\n",
    "attention_layer = nn.TransformerEncoderLayer(d_model=dim, nhead=heads, dim_feedforward=dim*4,\n",
    "                                                activation='gelu', dropout=dropout, batch_first=True)\n",
    "fusion_encoder = nn.TransformerEncoder(attention_layer, layers).cuda()\n",
    "encoding = fusion_encoder(input, src_key_padding_mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs = {\n",
    "    'actors': actors,\n",
    "    'encoding': encoding,\n",
    "    'mask': mask,\n",
    "    'route_lanes': inputs['route_lanes']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_outputs = {}\n",
    "\n",
    "# shape = (32, 1+N, 5)\n",
    "current_states = encoder_outputs['actors'][:, :, -1]\n",
    "# shape = (32, 200+15+21, 256)\n",
    "encoding, mask = encoder_outputs['encoding'], encoder_outputs['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = 10\n",
    "modalities = 6\n",
    "levels = 3\n",
    "\n",
    "class GMMPredictor(nn.Module):\n",
    "    def __init__(self, modalities=6):\n",
    "        super(GMMPredictor, self).__init__()\n",
    "        self.modalities = modalities\n",
    "        self._future_len = 80\n",
    "        self.gaussian = nn.Sequential(nn.Linear(256, 512), nn.ELU(), nn.Dropout(0.1), nn.Linear(512, self._future_len*4))\n",
    "        self.score = nn.Sequential(nn.Linear(256, 64), nn.ELU(), nn.Linear(64, 1))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        B, N, M, _ = input.shape\n",
    "        traj = self.gaussian(input).view(B, N, M, self._future_len, 4) # mu_x, mu_y, log_sig_x, log_sig_y\n",
    "        score = self.score(input).squeeze(-1)\n",
    "\n",
    "        return traj, score\n",
    "\n",
    "\n",
    "class InitialPredictionDecoder(nn.Module):\n",
    "    def __init__(self, modalities, neighbors, dim=256):\n",
    "        super(InitialPredictionDecoder, self).__init__()\n",
    "        self._modalities = modalities\n",
    "        self._agents = neighbors + 1\n",
    "        self.multi_modal_query_embedding = nn.Embedding(modalities, dim)\n",
    "        self.agent_query_embedding = nn.Embedding(self._agents, dim)\n",
    "        self.query_encoder = CrossTransformer()\n",
    "        self.predictor = GMMPredictor()\n",
    "        self.register_buffer('modal', torch.arange(modalities).long())\n",
    "        self.register_buffer('agent', torch.arange(self._agents).long())\n",
    "\n",
    "    def forward(self, current_states, encoding, mask):\n",
    "        N = self._agents   # N = 1 + 10 = 11\n",
    "        multi_modal_query = self.multi_modal_query_embedding(self.modal)   # 可学习的嵌入向量\n",
    "        # self.modal.shape = (6)\n",
    "        # multi_modal_query.shape = (6, 256)\n",
    "        agent_query = self.agent_query_embedding(self.agent)\n",
    "        # self.agent.shape = (N)\n",
    "        # agent_query.shape = (N, 256)\n",
    "        query = encoding[:, :N, None] + multi_modal_query[None, :, :] + agent_query[:, None, :]\n",
    "        query_content = torch.stack([self.query_encoder(query[:, i], encoding, encoding, mask) for i in range(N)], dim=1)\n",
    "        # query.shape = (32, N, M, 256)\n",
    "        # query_content.shape = (32, N, M, 256)\n",
    "        predictions, scores = self.predictor(query_content)\n",
    "        # predictions.shape = (32, N, M, 4 * T, 4), mu_x, mu_y, log_sig_x, log_sig_y\n",
    "        # scores.shape = (32, N, M)\n",
    "        predictions[..., :2] += current_states[:, :N, None, None, :2]\n",
    "\n",
    "        return query_content, predictions, scores\n",
    "    \n",
    "initial_predictor = InitialPredictionDecoder(modalities, neighbors).cuda()\n",
    "last_content, last_level, last_score = initial_predictor(current_states, encoding, mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# level 0 decode\n",
    "last_content, last_level, last_score = initial_predictor(current_states, encoding, mask)\n",
    "decoder_outputs['level_0_interactions'] = last_level\n",
    "decoder_outputs['level_0_scores'] = last_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_encoder = FutureEncoder().cuda()\n",
    "# 把这个网络复制2份\n",
    "interaction_stage = nn.ModuleList([InteractionDecoder(modalities, future_encoder).cuda() for _ in range(levels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# level k reasoning\n",
    "for k in range(1, 3):\n",
    "    interaction_decoder = interaction_stage[k-1]\n",
    "    last_content, last_level, last_score = interaction_decoder(current_states, last_level, last_score, last_content, encoding, mask)\n",
    "    decoder_outputs[f'level_{k}_interactions'] = last_level\n",
    "    decoder_outputs[f'level_{k}_scores'] = last_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6, 256])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_encoding = last_content[:, 0]\n",
    "env_encoding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nuplan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
